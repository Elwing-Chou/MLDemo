{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "if not os.path.exists(\"imdb\"):\n",
    "    tar = tarfile.open(\"aclImdb_v1.tar.gz\")\n",
    "    tar.extractall(\"imdb\")\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24995</td>\n",
       "      <td>Towards the end of the movie, I felt it was to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24996</td>\n",
       "      <td>This is the kind of movie that my enemies cont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24997</td>\n",
       "      <td>I saw 'Descent' last night at the Stockholm Fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24998</td>\n",
       "      <td>Some films that you pick up for a pound turn o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24999</td>\n",
       "      <td>This is one of the dumbest films, I've ever se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  sentiment\n",
       "0      Bromwell High is a cartoon comedy. It ran at t...          1\n",
       "1      Homelessness (or Houselessness as George Carli...          1\n",
       "2      Brilliant over-acting by Lesley Ann Warren. Be...          1\n",
       "3      This is easily the most underrated film inn th...          1\n",
       "4      This is not the typical Mel Brooks film. It wa...          1\n",
       "...                                                  ...        ...\n",
       "24995  Towards the end of the movie, I felt it was to...          0\n",
       "24996  This is the kind of movie that my enemies cont...          0\n",
       "24997  I saw 'Descent' last night at the Stockholm Fi...          0\n",
       "24998  Some films that you pick up for a pound turn o...          0\n",
       "24999  This is one of the dumbest films, I've ever se...          0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "base = \"imdb/aclImdb/train/\"\n",
    "\n",
    "postxt = []\n",
    "pos = glob.glob(base + \"pos/*.txt\")\n",
    "for p in pos:\n",
    "    with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "        postxt.append(f.read())\n",
    "\n",
    "negtxt = []\n",
    "neg = glob.glob(base + \"neg/*.txt\")\n",
    "for n in neg:\n",
    "    with open(n, \"r\", encoding=\"utf-8\") as f:\n",
    "        negtxt.append(f.read())\n",
    "        \n",
    "train = pd.DataFrame({\n",
    "    \"content\":postxt + negtxt,\n",
    "    \"sentiment\":[1] * len(postxt) + [0] * len(negtxt)\n",
    "})\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24995</td>\n",
       "      <td>I occasionally let my kids watch this garbage ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24996</td>\n",
       "      <td>When all we have anymore is pretty much realit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24997</td>\n",
       "      <td>The basic genre is a thriller intercut with an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24998</td>\n",
       "      <td>Four things intrigued me as to this film - fir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24999</td>\n",
       "      <td>David Bryce's comments nearby are exceptionall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  sentiment\n",
       "0      I went and saw this movie last night after bei...          1\n",
       "1      Actor turned director Bill Paxton follows up h...          1\n",
       "2      As a recreational golfer with some knowledge o...          1\n",
       "3      I saw this film in a sneak preview, and it is ...          1\n",
       "4      Bill Paxton has taken the true story of the 19...          1\n",
       "...                                                  ...        ...\n",
       "24995  I occasionally let my kids watch this garbage ...          0\n",
       "24996  When all we have anymore is pretty much realit...          0\n",
       "24997  The basic genre is a thriller intercut with an...          0\n",
       "24998  Four things intrigued me as to this film - fir...          0\n",
       "24999  David Bryce's comments nearby are exceptionall...          0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "base = \"imdb/aclImdb/test/\"\n",
    "\n",
    "postxt = []\n",
    "pos = glob.glob(base + \"pos/*.txt\")\n",
    "for p in pos:\n",
    "    with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "        postxt.append(f.read())\n",
    "\n",
    "negtxt = []\n",
    "neg = glob.glob(base + \"neg/*.txt\")\n",
    "for n in neg:\n",
    "    with open(n, \"r\", encoding=\"utf-8\") as f:\n",
    "        negtxt.append(f.read())\n",
    "        \n",
    "test = pd.DataFrame({\n",
    "    \"content\":postxt + negtxt,\n",
    "    \"sentiment\":[1] * len(postxt) + [0] * len(negtxt)\n",
    "})\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1. 幫你列出所有出現過的詞\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tok = Tokenizer(num_words=2000)\n",
    "tok.fit_on_texts(train[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 如果你要看詞轉化的數字\n",
    "# tok.word_index\n",
    "# 根據出現次數做一個排序: \n",
    "# sorted(tok.word_counts.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1701</th>\n",
       "      <th>1702</th>\n",
       "      <th>1703</th>\n",
       "      <th>1704</th>\n",
       "      <th>1705</th>\n",
       "      <th>1706</th>\n",
       "      <th>1707</th>\n",
       "      <th>1708</th>\n",
       "      <th>1709</th>\n",
       "      <th>1710</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1069</td>\n",
       "      <td>209</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>169.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>739</td>\n",
       "      <td>44</td>\n",
       "      <td>74</td>\n",
       "      <td>32</td>\n",
       "      <td>1829</td>\n",
       "      <td>15</td>\n",
       "      <td>150.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>526</td>\n",
       "      <td>117</td>\n",
       "      <td>113</td>\n",
       "      <td>31</td>\n",
       "      <td>1957</td>\n",
       "      <td>115</td>\n",
       "      <td>902</td>\n",
       "      <td>758</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>711</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>249</td>\n",
       "      <td>91.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>797</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>73.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24995</td>\n",
       "      <td>946</td>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>417</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24996</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>58</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24997</td>\n",
       "      <td>10</td>\n",
       "      <td>216</td>\n",
       "      <td>233</td>\n",
       "      <td>311</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1411</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24998</td>\n",
       "      <td>46</td>\n",
       "      <td>105</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>1259</td>\n",
       "      <td>53</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>468.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24999</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>204</td>\n",
       "      <td>123</td>\n",
       "      <td>107.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 1711 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7       8      9     ...  \\\n",
       "0       309     6     3  1069   209     9    30     1   169.0   55.0  ...   \n",
       "1        39    14   739    44    74    32  1829    15   150.0   18.0  ...   \n",
       "2       526   117   113    31  1957   115   902   758    10.0   25.0  ...   \n",
       "3        11     6   711     1    88    19     1   249    91.0    9.0  ...   \n",
       "4        11     6    21     1   797    19     9    13    73.0  326.0  ...   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...     ...    ...  ...   \n",
       "24995   946     1   127     4     1    17    10   417     9.0   13.0  ...   \n",
       "24996    11     6     1   240     4    17    12    58  1496.0   10.0  ...   \n",
       "24997    10   216   233   311    30     1    19  1411     2.0    9.0  ...   \n",
       "24998    46   105    12    22  1259    53    15     3   468.0   43.0  ...   \n",
       "24999    11     6    28     4     1   105   204   123   107.0    9.0  ...   \n",
       "\n",
       "       1701  1702  1703  1704  1705  1706  1707  1708  1709  1710  \n",
       "0       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "24995   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "24996   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "24997   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "24998   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "24999   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[25000 rows x 1711 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step2. 根據剛才統計的辭典, 把每一個詞化成一個數字\n",
    "# !!! 2000以外的詞都丟掉了\n",
    "x_train_num = tok.texts_to_sequences(train[\"content\"])\n",
    "x_test_num = tok.texts_to_sequences(test[\"content\"])\n",
    "pd.DataFrame(x_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (optional) 你可以查查看每一個數字代表什麼詞\n",
    "reverse_index = {v:k for k, v in tok.word_index.items()}\n",
    "reverse_index[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>309</td>\n",
       "      <td>6</td>\n",
       "      <td>227</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1983</td>\n",
       "      <td>15</td>\n",
       "      <td>501</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>26</td>\n",
       "      <td>67</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>276</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>77</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>335</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>254</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>176</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>164</td>\n",
       "      <td>2</td>\n",
       "      <td>561</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>73</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>196</td>\n",
       "      <td>253</td>\n",
       "      <td>65</td>\n",
       "      <td>528</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24995</td>\n",
       "      <td>156</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>112</td>\n",
       "      <td>194</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>769</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>845</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>411</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>302</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>539</td>\n",
       "      <td>507</td>\n",
       "      <td>41</td>\n",
       "      <td>1568</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24997</td>\n",
       "      <td>806</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>58</td>\n",
       "      <td>1172</td>\n",
       "      <td>900</td>\n",
       "      <td>1227</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>423</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24998</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>105</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>1259</td>\n",
       "      <td>53</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>468</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>1138</td>\n",
       "      <td>278</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>105</td>\n",
       "      <td>8</td>\n",
       "      <td>260</td>\n",
       "      <td>1195</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>39</td>\n",
       "      <td>275</td>\n",
       "      <td>89</td>\n",
       "      <td>434</td>\n",
       "      <td>126</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1    2    3    4     5    6     7    8    9    ...  190   191  \\\n",
       "0        0     0    0    0    0     0    0     0    0    0  ...  101    12   \n",
       "1        1  1983   15  501  206     1   45    26   67   78  ...    7    39   \n",
       "2        0     0    0    0    0     0    0     0    0    0  ...  125   254   \n",
       "3        0     0    0    0    0     0    0     0    0    0  ...    3   164   \n",
       "4        0     0    0    0    0     0    0     0    0    0  ...    8     1   \n",
       "...    ...   ...  ...  ...  ...   ...  ...   ...  ...  ...  ...  ...   ...   \n",
       "24995  156    18   10  112  194    41    9   769    3    5  ...  845    18   \n",
       "24996    0     0    0    0    0     0    0     0    0    0  ...  302   103   \n",
       "24997  806    11   17   43   58  1172  900  1227    5    1  ...   54    10   \n",
       "24998    0    46  105   12   22  1259   53    15    3  468  ...   18  1138   \n",
       "24999    0     0    0    0    0     0    0     0    0    0  ...   55    39   \n",
       "\n",
       "       192  193  194  195   196  197   198   199  \n",
       "0      309    6  227   48     3   12     9   215  \n",
       "1      276   11   19   77    22    5   335   405  \n",
       "2       55   10   64    9    60    6   176   396  \n",
       "3        2  561   21   35    73   14     3   482  \n",
       "4       17   18    2  196   253   65   528    70  \n",
       "...    ...  ...  ...  ...   ...  ...   ...   ...  \n",
       "24995    9   13  250    5   103    3   411    76  \n",
       "24996    3  539  507   41  1568   37     4     1  \n",
       "24997   40  423   76   80    11   17    96    75  \n",
       "24998  278    2  131  105     8  260  1195   794  \n",
       "24999  275   89  434  126    55   11     6  1350  \n",
       "\n",
       "[25000 rows x 200 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step3. 把每一篇文章截長補短變成一樣多的詞數\n",
    "# 截長: 後面截的\n",
    "# 補短: 補0\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "x_train_num_pad = pad_sequences(x_train_num, maxlen=200)\n",
    "x_test_num_pad = pad_sequences(x_test_num, maxlen=200)\n",
    "pd.DataFrame(x_train_num_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 200, 32)           64000     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               1638656   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,702,913\n",
      "Trainable params: 1,702,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "model = Sequential()\n",
    "model.add(Embedding(2000, 32, input_length=200))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"sentiment\"]\n",
    "y_test = test[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.5033 - acc: 0.7352 - val_loss: 0.3182 - val_acc: 0.8624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eace00c7c8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_num_pad, y_train,\n",
    "          batch_size=200, \n",
    "          epochs=1,\n",
    "          validation_split=0.1, \n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 52us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.321740517244339, 0.85964]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_num_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原本情緒: 正面\n",
      "預測情緒: 負面\n",
      "原文: Even if you're a fan of Jean Rollin's idiosyncratic body of work, you will be caught off guard by this exceptional foray into science fiction territory. For once, there's not a single diaphanously gowned vampire girl in sight ! True to tradition, the budget proved way too tight to realize the director's vision entirely. Yet this is largely compensated by his obvious love of genre cinema, dedication to his craft and sheer ingenuity. Jean-Claude Couty's atmospheric cinematography makes the most of the foreboding locations and Philippe Bréjean (a/k/a \"Gary Sandeur\") contributes a startling soundtrack that fortunately doesn't resemble any of the sappy stuff he composed for hardcore.<br /><br />Shot in and around a Paris office block before and after working hours, the film was largely cast with porn regulars Rollin was already quite familiar with from his \"Michel Gentil\" cash-gathering XXX efforts, most notably French f*ck film royalty Brigitte Lahaie in the demanding lead. Playing Elisabeth (rather well, I might add), she's picked up wandering a nearby highway one night by Robert (Vincent Gardère), driving home at the end of a long work day. Barely able to piece together the string of events that got her there, Elisabeth seems to lose her memories mere moments after events occur, even forgetting Robert's name and heroic savior role before their night flight comes to an end at his apartment. Prior to making love, she rightfully describes herself as a virgin (further credit to Brigitte's thespian skills that she can handle the line so convincingly, being after all one of the more active adult actresses of the '70s) because she cannot recall a single touch preceding his. Because of this nifty bit of context, the relatively long sex scene that follows totally eschews the gratuity of other \"commercial\" interludes Rollin has had to include in other works to assure funding.<br /><br />When Robert leaves for work, he's inevitably erased from Elisabeth's feeble mind. A mysterious doctor (comedian Bernard Papineau effectively cast against type) and his menacing assistant Solange (striking porn starlet Rachel Mhas) move in on her during her protector's absence and take her back to the place she turns out to have escaped from. Here we get one of the movie's strongest scenes as she's re-introduced to her roommate Catherine (the late Cathérine Greiner a/k/a hardcore performer \"Cathy Stewart\" in a quietly devastating turn), both girls desperately supplying fictitious shared \"memories\" for one another in a bid to outrun their inevitable fate. That deterioration is not solely limited to the mind becomes painfully clear when they are served lunch and Catherine's unable to control her movements in trying to eat a spoonful of soup. It's also Catherine who gets to voice the filmmaker's compromise with the demands of commerce as she urges Elisabeth to get naked and hold her because sex is all they have left now that both mind and physical faculties have deserted them.<br /><br />Several rather explicit - if not quite hardcore - sex scenes make up the movie's mid-section and French porn aficionados should recognize the likes of Alain Plumey (a/k/a \"Cyril Val\"), Jacques Gateau and Elodie Delage, along with a blink and miss bit from future porno princess Marilyn Jess whose rape at the hands, mouth and member of Plumey was only present in the film's rarely screened XXX version FILLES TRAQUEES. The pivotal part of Véronique, a girl Elisabeth almost seems to remember and whom she seeks to escape anew with, is beautifully handled by the exquisite Dominique Journet - in her unforgettable debut - who would go on to play a sizable supporting role in Franco Zeffirelli's LA TRAVIATA. The six feet under ending reveals the deteriorating condition to be the result of a nuclear spill, the quarantined \"patients\" ultimately leaving a barely breathing empty shell, unceremoniously disposed off in a fiery furnace. The final shot offers a particularly heartbreaking variation on that of Chaplin's MODERN TIMES as Elisabeth, approaching complete meltdown by now, and a wounded Robert stumble along the railroad bridge, clumsily clasping each other's outstretched hands.\n"
     ]
    }
   ],
   "source": [
    "# 挑一篇預測錯誤的來看\n",
    "import numpy as np\n",
    "pre = model.predict_classes(x_test_num_pad).reshape(-1)\n",
    "y_test_np = np.array(y_test).reshape(-1)\n",
    "noneq = pre != y_test_np\n",
    "idx = np.nonzero(noneq)[0]\n",
    "first = idx[0]\n",
    "s = [\"負面\", \"正面\"]\n",
    "print(\"原本情緒:\", s[y_test_np[first]])\n",
    "print(\"預測情緒:\", s[pre[first]])\n",
    "print(\"原文:\", test[\"content\"][first])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>負面(預測)</th>\n",
       "      <th>正面(預測)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>負面(答案)</td>\n",
       "      <td>10654</td>\n",
       "      <td>1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>正面(答案)</td>\n",
       "      <td>1663</td>\n",
       "      <td>10837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        負面(預測)  正面(預測)\n",
       "負面(答案)   10654    1846\n",
       "正面(答案)    1663   10837"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "s = [\"負面\", \"正面\"]\n",
    "row = [c + \"(答案)\" for c in s]\n",
    "col = [c + \"(預測)\" for c in s]\n",
    "pd.DataFrame(confusion_matrix(y_test_np, pre),\n",
    "             columns=col,\n",
    "             index=row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 1, 32)             64000     \n",
      "=================================================================\n",
      "Total params: 64,000\n",
      "Trainable params: 64,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 拿出副產物是大部分語言模型會做的事\n",
    "w = model.layers[0].get_weights()\n",
    "from keras.models import Sequential\n",
    "embed = Sequential()\n",
    "embed.add(Embedding(2000, 32, input_length=1))\n",
    "embed.layers[0].set_weights(w)\n",
    "embed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "詞: band\n",
      "[[[-0.03678256  0.03467375  0.0136328   0.03134776  0.02761905\n",
      "    0.02330947 -0.04993657 -0.02100598 -0.03225459  0.00487366\n",
      "    0.01979636 -0.03665241  0.03823897  0.03968673 -0.00142444\n",
      "   -0.04762316 -0.0476406   0.04715921  0.01021596 -0.04522716\n",
      "    0.03873352 -0.04564768  0.00658088 -0.03555476  0.00324341\n",
      "    0.02172791  0.0449718   0.02711388  0.01002748  0.03876592\n",
      "   -0.03908352  0.04889998]]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "c = random.randint(1, 2000)\n",
    "print(\"詞:\", reverse_index[c])\n",
    "print(embed.predict([c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 200, 32)           64000     \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 16)                784       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 69,393\n",
      "Trainable params: 69,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 如果我採用序列式(時間相關)模型\n",
    "# 情緒分析的時候其實你用不用RNN影響不大\n",
    "from keras.layers import SimpleRNN\n",
    "model = Sequential()\n",
    "model.add(Embedding(2000, 32, input_length=200))\n",
    "model.add(SimpleRNN(16))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.3430 - acc: 0.8581 - val_loss: 0.3881 - val_acc: 0.8228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ead57bfd48>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_num_pad, y_train,\n",
    "          batch_size=200, \n",
    "          epochs=1,\n",
    "          validation_split=0.1, \n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 5s 189us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.362357794675827, 0.8474]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_num_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
